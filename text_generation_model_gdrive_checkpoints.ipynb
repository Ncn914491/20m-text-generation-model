{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10M Parameter Text Generation Model with Google Drive Checkpoints\n",
    "## Resume Training After Colab Disconnections\n",
    "\n",
    "This notebook implements automatic checkpoint saving to Google Drive and seamless training resumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Mount Google Drive and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive with error handling\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Check if running in Colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"âš ï¸ Not running in Google Colab. Using local directory for checkpoints.\")\n",
    "\n",
    "# Mount Google Drive if in Colab\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        # Check if already mounted\n",
    "        if os.path.exists('/content/drive/MyDrive'):\n",
    "            print(\"âœ“ Google Drive already mounted\")\n",
    "        else:\n",
    "            print(\"Mounting Google Drive...\")\n",
    "            drive.mount('/content/drive', force_remount=False)\n",
    "            print(\"âœ“ Google Drive mounted successfully\")\n",
    "        \n",
    "        CHECKPOINT_DIR = '/content/drive/MyDrive/text_gen_checkpoints'\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Failed to mount Google Drive: {e}\")\n",
    "        print(\"Using local directory instead (checkpoints will be lost on disconnect)\")\n",
    "        CHECKPOINT_DIR = './checkpoints'\n",
    "else:\n",
    "    CHECKPOINT_DIR = './checkpoints'\n",
    "\n",
    "# Create checkpoint directory\n",
    "try:\n",
    "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "    print(f\"\\nðŸ“ Checkpoint directory: {CHECKPOINT_DIR}\")\n",
    "    print(f\"âœ“ Directory ready for saving checkpoints\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error creating checkpoint directory: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q transformers datasets tokenizers accelerate wandb evaluate rouge-score nltk sacrebleu\n",
    "!pip install -q sentencepiece protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Checkpoint Management Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, scheduler, epoch, step, train_loss, val_loss, checkpoint_dir, training_history=None):\n",
    "    \"\"\"Save checkpoint to Google Drive\"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'step': step,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'training_history': training_history or [],\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch{epoch}_step{step}.pt')\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    \n",
    "    # Save latest checkpoint reference\n",
    "    latest_path = os.path.join(checkpoint_dir, 'latest_checkpoint.txt')\n",
    "    with open(latest_path, 'w') as f:\n",
    "        f.write(checkpoint_path)\n",
    "    \n",
    "    print(f\"âœ“ Checkpoint saved: {os.path.basename(checkpoint_path)}\")\n",
    "    return checkpoint_path\n",
    "\n",
    "def load_latest_checkpoint(checkpoint_dir, model, optimizer, scheduler):\n",
    "    \"\"\"Load the latest checkpoint from Google Drive\"\"\"\n",
    "    latest_path = os.path.join(checkpoint_dir, 'latest_checkpoint.txt')\n",
    "    \n",
    "    if not os.path.exists(latest_path):\n",
    "        print(\"No checkpoint found. Starting from scratch.\")\n",
    "        return None\n",
    "    \n",
    "    with open(latest_path, 'r') as f:\n",
    "        checkpoint_path = f.read().strip()\n",
    "    \n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(\"Checkpoint file not found. Starting from scratch.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Loading checkpoint: {os.path.basename(checkpoint_path)}\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    print(f\"âœ“ Resumed from epoch {checkpoint['epoch']}, step {checkpoint['step']}\")\n",
    "    print(f\"  Previous train loss: {checkpoint['train_loss']:.4f}\")\n",
    "    if checkpoint['val_loss'] > 0:\n",
    "        print(f\"  Previous val loss: {checkpoint['val_loss']:.4f}\")\n",
    "    \n",
    "    return checkpoint\n",
    "\n",
    "def cleanup_old_checkpoints(checkpoint_dir, keep_last=3):\n",
    "    \"\"\"Keep only the last N checkpoints to save space\"\"\"\n",
    "    checkpoints = sorted(glob.glob(os.path.join(checkpoint_dir, 'checkpoint_*.pt')))\n",
    "    \n",
    "    if len(checkpoints) > keep_last:\n",
    "        for old_checkpoint in checkpoints[:-keep_last]:\n",
    "            try:\n",
    "                os.remove(old_checkpoint)\n",
    "                print(f\"  Removed old checkpoint: {os.path.basename(old_checkpoint)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Warning: Could not remove {os.path.basename(old_checkpoint)}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPT2Config(\n",
    "    vocab_size=50257,\n",
    "    n_positions=512,\n",
    "    n_embd=256,\n",
    "    n_layer=8,\n",
    "    n_head=8,\n",
    "    n_inner=1024,\n",
    "    activation_function='gelu_new',\n",
    "    resid_pdrop=0.1,\n",
    "    embd_pdrop=0.1,\n",
    "    attn_pdrop=0.1,\n",
    ")\n",
    "\n",
    "model = GPT2LMHeadModel(config).to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Model size: {total_params * 4 / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "dataset = load_dataset('wikitext', 'wikitext-103-v1')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "tokenized_train = dataset['train'].map(tokenize_function, batched=True, remove_columns=dataset['train'].column_names)\n",
    "tokenized_val = dataset['validation'].map(tokenize_function, batched=True, remove_columns=dataset['validation'].column_names)\n",
    "\n",
    "tokenized_train.set_format('torch')\n",
    "tokenized_val.set_format('torch')\n",
    "\n",
    "print(f\"Train samples: {len(tokenized_train)}\")\n",
    "print(f\"Val samples: {len(tokenized_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 5e-4\n",
    "EPOCHS = 3\n",
    "WARMUP_STEPS = 500\n",
    "GRADIENT_ACCUMULATION_STEPS = 4\n",
    "MAX_GRAD_NORM = 1.0\n",
    "CHECKPOINT_EVERY_N_STEPS = 500  # Save checkpoint every N steps\n",
    "\n",
    "train_loader = DataLoader(tokenized_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(tokenized_val, batch_size=BATCH_SIZE)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "total_steps = len(train_loader) * EPOCHS // GRADIENT_ACCUMULATION_STEPS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=total_steps)\n",
    "\n",
    "print(f\"Total training steps: {total_steps}\")\n",
    "print(f\"Checkpoints will be saved every {CHECKPOINT_EVERY_N_STEPS} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Check for Existing Checkpoint and Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load existing checkpoint\n",
    "checkpoint = load_latest_checkpoint(CHECKPOINT_DIR, model, optimizer, scheduler)\n",
    "\n",
    "# Set starting point\n",
    "if checkpoint:\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    start_step = checkpoint['step']\n",
    "    training_history = checkpoint.get('training_history', [])\n",
    "    print(f\"\\nðŸ”„ Resuming training from epoch {start_epoch}, step {start_step}\")\n",
    "else:\n",
    "    start_epoch = 1\n",
    "    start_step = 0\n",
    "    training_history = []\n",
    "    print(\"\\nðŸ†• Starting fresh training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Training Loop with Auto-Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "            total_loss += outputs.loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    perplexity = torch.exp(torch.tensor(avg_loss))\n",
    "    return avg_loss, perplexity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop with checkpoint support\n",
    "best_val_loss = float('inf')\n",
    "global_step = start_step\n",
    "\n",
    "try:\n",
    "    for epoch in range(start_epoch, EPOCHS + 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Epoch {epoch}/{EPOCHS}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f\"Training Epoch {epoch}\")\n",
    "        \n",
    "        # Calculate starting batch index for resume\n",
    "        if epoch == start_epoch and start_step > 0:\n",
    "            # Calculate how many batches to skip based on global_step\n",
    "            batches_completed = (start_step * GRADIENT_ACCUMULATION_STEPS) % len(train_loader)\n",
    "            print(f\"Resuming from batch {batches_completed}/{len(train_loader)}\")\n",
    "        else:\n",
    "            batches_completed = 0\n",
    "        \n",
    "        for step, batch in enumerate(progress_bar):\n",
    "            # Skip already completed batches when resuming\n",
    "            if epoch == start_epoch and step < batches_completed:\n",
    "                continue\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "            loss = outputs.loss / GRADIENT_ACCUMULATION_STEPS\n",
    "            loss.backward()\n",
    "            \n",
    "            if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "            \n",
    "            total_loss += loss.item() * GRADIENT_ACCUMULATION_STEPS\n",
    "            progress_bar.set_postfix({'loss': loss.item() * GRADIENT_ACCUMULATION_STEPS, 'step': global_step})\n",
    "            \n",
    "            # Save checkpoint periodically\n",
    "            if global_step % CHECKPOINT_EVERY_N_STEPS == 0 and global_step > start_step:\n",
    "                avg_train_loss = total_loss / (step + 1 - batches_completed)\n",
    "                val_loss, val_perplexity = evaluate(model, val_loader, device)\n",
    "                \n",
    "                save_checkpoint(model, optimizer, scheduler, epoch, global_step, avg_train_loss, val_loss, CHECKPOINT_DIR, training_history)\n",
    "                cleanup_old_checkpoints(CHECKPOINT_DIR, keep_last=3)\n",
    "                \n",
    "                model.train()  # Back to training mode\n",
    "        \n",
    "        # End of epoch evaluation\n",
    "        avg_train_loss = total_loss / (len(train_loader) - batches_completed)\n",
    "        val_loss, val_perplexity = evaluate(model, val_loader, device)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch} Results:\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"  Val Perplexity: {val_perplexity:.2f}\")\n",
    "        \n",
    "        training_history.append({\n",
    "            'epoch': epoch,\n",
    "            'train_loss': avg_train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'val_perplexity': val_perplexity,\n",
    "            'global_step': global_step\n",
    "        })\n",
    "        \n",
    "        # Save end-of-epoch checkpoint\n",
    "        save_checkpoint(model, optimizer, scheduler, epoch, global_step, avg_train_loss, val_loss, CHECKPOINT_DIR, training_history)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_path = os.path.join(CHECKPOINT_DIR, 'best_model.pt')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'val_perplexity': val_perplexity\n",
    "            }, best_model_path)\n",
    "            print(f\"âœ“ Saved best model (val_loss: {val_loss:.4f})\")\n",
    "        \n",
    "        cleanup_old_checkpoints(CHECKPOINT_DIR, keep_last=3)\n",
    "        \n",
    "        # Reset batches_completed for next epoch\n",
    "        batches_completed = 0\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… Training completed successfully!\")\n",
    "    print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nâš ï¸ Training interrupted by user\")\n",
    "    print(\"Saving checkpoint before exit...\")\n",
    "    avg_train_loss = total_loss / max(step + 1 - batches_completed, 1)\n",
    "    save_checkpoint(model, optimizer, scheduler, epoch, global_step, avg_train_loss, 0.0, CHECKPOINT_DIR, training_history)\n",
    "    print(\"âœ“ Checkpoint saved. You can resume training later.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Error occurred: {e}\")\n",
    "    print(\"Saving emergency checkpoint...\")\n",
    "    try:\n",
    "        save_checkpoint(model, optimizer, scheduler, epoch, global_step, 0.0, 0.0, CHECKPOINT_DIR, training_history)\n",
    "    except:\n",
    "        print(\"Could not save emergency checkpoint\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Save Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history to Google Drive\n",
    "history_path = os.path.join(CHECKPOINT_DIR, 'training_history.json')\n",
    "with open(history_path, 'w') as f:\n",
    "    json.dump(training_history, f, indent=2)\n",
    "\n",
    "print(f\"Training history saved to: {history_path}\")\n",
    "\n",
    "# Display training progress\n",
    "if training_history:\n",
    "    print(\"\\nTraining Progress:\")\n",
    "    for record in training_history:\n",
    "        print(f\"Epoch {record['epoch']}: Train Loss={record['train_loss']:.4f}, Val Loss={record['val_loss']:.4f}, Perplexity={record['val_perplexity']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=100, temperature=0.8, top_k=50, top_p=0.95):\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_length,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "            top_p=top_p,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Test generation\n",
    "prompts = [\n",
    "    \"The future of artificial intelligence\",\n",
    "    \"In a world where technology\",\n",
    "    \"Scientists have discovered\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Text Generation Examples\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    print(\"-\" * 60)\n",
    "    generated = generate_text(prompt, max_length=150)\n",
    "    print(generated)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Save Final Model to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "final_model_dir = os.path.join(CHECKPOINT_DIR, 'final_model')\n",
    "model.save_pretrained(final_model_dir)\n",
    "tokenizer.save_pretrained(final_model_dir)\n",
    "\n",
    "print(f\"âœ“ Final model saved to: {final_model_dir}\")\n",
    "print(\"\\nYour model is safely stored in Google Drive and can be loaded anytime!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Load Model from Checkpoint (For Inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load the best model for inference\n",
    "def load_best_model_for_inference():\n",
    "    best_model_path = os.path.join(CHECKPOINT_DIR, 'best_model.pt')\n",
    "    \n",
    "    if os.path.exists(best_model_path):\n",
    "        checkpoint = torch.load(best_model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"âœ“ Loaded best model from epoch {checkpoint['epoch']}\")\n",
    "        print(f\"  Val Loss: {checkpoint['val_loss']:.4f}\")\n",
    "        print(f\"  Val Perplexity: {checkpoint['val_perplexity']:.2f}\")\n",
    "        return model\n",
    "    else:\n",
    "        print(\"No best model found. Using current model.\")\n",
    "        return model\n",
    "\n",
    "# Uncomment to load best model\n",
    "# model = load_best_model_for_inference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Checkpoint Management Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all available checkpoints\n",
    "def list_checkpoints():\n",
    "    checkpoints = sorted(glob.glob(os.path.join(CHECKPOINT_DIR, 'checkpoint_*.pt')))\n",
    "    \n",
    "    if not checkpoints:\n",
    "        print(\"No checkpoints found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nAvailable checkpoints in {CHECKPOINT_DIR}:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for cp in checkpoints:\n",
    "        try:\n",
    "            checkpoint = torch.load(cp, map_location='cpu')\n",
    "            size_mb = os.path.getsize(cp) / (1024 * 1024)\n",
    "            print(f\"\\n{os.path.basename(cp)}\")\n",
    "            print(f\"  Epoch: {checkpoint['epoch']}, Step: {checkpoint['step']}\")\n",
    "            print(f\"  Train Loss: {checkpoint['train_loss']:.4f}, Val Loss: {checkpoint['val_loss']:.4f}\")\n",
    "            print(f\"  Size: {size_mb:.2f} MB\")\n",
    "            print(f\"  Timestamp: {checkpoint.get('timestamp', 'N/A')}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n{os.path.basename(cp)} - Error loading: {e}\")\n",
    "\n",
    "# Run to see all checkpoints\n",
    "list_checkpoints()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
